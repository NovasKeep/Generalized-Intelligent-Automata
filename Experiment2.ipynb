{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Cellular Automata Test\n",
    "The goal of this project is to experiment with a new paradigm for generalized intelligence, inspired heavily by [this](https://www.youtube.com/watch?v=p-OYPRhqRCg) talk between Joscha Bach and Michael Levin. The ideas I'm drawing upon are primarily Bachs, however I take heavy inspiration by Levins work on collective intelligence in all forms of cells as well, seeking originally to make one based mostly on the idea of bioelectric signaling, and slowly shifting more towards Joscha Bachs idea on a search for selector_functions to find appropraite neighbors in higher dimensions to process information over long distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_activation(neighbors):\n",
    "    if neighbors:\n",
    "        return sum(neighbor.state for neighbor in neighbors) / len(neighbors)\n",
    "    return 0\n",
    "\n",
    "def inverted_average(neighbors):\n",
    "    if neighbors:\n",
    "        return 1-(sum(neighbor.state for neighbor in neighbors) / len(neighbors))\n",
    "    return 0\n",
    "\n",
    "def sigmoid_activation(neighbors):\n",
    "    total = sum(neighbor.state for neighbor in neighbors) if neighbors else 0\n",
    "    return 1 / (1 + np.exp(-total))\n",
    "\n",
    "def min_activation(neighbors):\n",
    "    if neighbors:\n",
    "        return min(neighbor.state for neighbor in neighbors)\n",
    "    return 0\n",
    "\n",
    "def max_activation(neighbors):\n",
    "    if neighbors:\n",
    "        return max(neighbor.state for neighbor in neighbors)\n",
    "    return 0\n",
    "\n",
    "def tanh_activation(neighbors):\n",
    "    total = sum(neighbor.state for neighbor in neighbors) if neighbors else 0\n",
    "    return (np.tanh(total) + 1) / 2  # Adjusting to [0, 1] range\n",
    "\n",
    "def random_activation(neighbors):\n",
    "    return (np.random.rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique directory name based on the current date and time\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "experiment_dir = f'Experiments/Experiment_2/Experiment_{current_time}'\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "def save_grid_data(grid, step, save_dir):\n",
    "    with open(f'{save_dir}/grid_data.csv', 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in grid:\n",
    "            writer.writerow([step] + [cell.state for cell in row])\n",
    "\n",
    "\n",
    "\n",
    "def save_grid_image(grid, step, save_dir):\n",
    "    image = np.array([[cell.state for cell in row] for row in grid])\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'Step {step}')\n",
    "    plt.savefig(f'{save_dir}/step_{step}.png')\n",
    "    plt.close()\n",
    "\n",
    "def create_images_from_csv(save_dir):\n",
    "    with open(f'{save_dir}/grid_data.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        current_step = -1\n",
    "        grid = []\n",
    "\n",
    "        for row in reader:\n",
    "            step = int(row[0])\n",
    "            if step != current_step:\n",
    "                if current_step != -1:\n",
    "                    # Save the previous step's image\n",
    "                    grid_array = np.array(grid)\n",
    "                    plt.imshow(grid_array, cmap='gray')\n",
    "                    plt.title(f'Step {current_step}')\n",
    "                    plt.savefig(f'{save_dir}/step_{current_step}.png')\n",
    "                    plt.close()\n",
    "\n",
    "                current_step = step\n",
    "                grid = []\n",
    "\n",
    "            grid.append([float(cell) for cell in row[1:]])\n",
    "\n",
    "        # Save the last step's image\n",
    "        if grid:\n",
    "            grid_array = np.array(grid)\n",
    "            plt.imshow(grid_array, cmap='gray')\n",
    "            plt.title(f'Step {current_step}')\n",
    "            plt.savefig(f'{save_dir}/step_{current_step}.png')\n",
    "            plt.close()\n",
    "\n",
    "def create_gif(image_folder, gif_name):\n",
    "    images = []\n",
    "\n",
    "    def sort_key(file_name):\n",
    "        numbers = re.findall(r'\\d+', file_name)\n",
    "        return int(numbers[0]) if numbers else 0\n",
    "\n",
    "    file_names = sorted(os.listdir(image_folder), key=sort_key)\n",
    "\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith('.png'):\n",
    "            file_path = os.path.join(image_folder, file_name)\n",
    "            images.append(imageio.imread(file_path))\n",
    "\n",
    "    imageio.mimsave(os.path.join(image_folder, gif_name), images, fps=10)\n",
    "\n",
    "    for file_name in file_names:\n",
    "            if file_name.endswith('.png'):\n",
    "                file_path = os.path.join(image_folder, file_name)\n",
    "                os.remove(file_path)\n",
    "\n",
    "class Cell:\n",
    "    def __init__(self, x, y, activation_function, num_neighbors=4):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.state = 0.0\n",
    "        self.reward = 0.0\n",
    "        self.memory = []\n",
    "        self.neighbors = []\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.connection_strength = {neighbor: 0.5 for neighbor in self.neighbors}\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def update_selector(self, update_cells=None):\n",
    "        # If no specific cells are provided, update all\n",
    "        if update_cells is None:\n",
    "            update_cells = range(self.num_neighbors)\n",
    "\n",
    "        # Update the specified neighbors\n",
    "        for i in update_cells:\n",
    "            # Randomly select a new neighbor\n",
    "            new_neighbor_x = np.random.randint(0, grid_size[0])\n",
    "            new_neighbor_y = np.random.randint(0, grid_size[1])\n",
    "            new_neighbor = (new_neighbor_x, new_neighbor_y)\n",
    "\n",
    "            # Replace the old neighbor with the new one\n",
    "            if i < len(self.neighbors):\n",
    "                self.neighbors[i] = new_neighbor\n",
    "            else:\n",
    "                self.neighbors.append(new_neighbor)\n",
    "\n",
    "            # Initialize connection strength for the new neighbor\n",
    "            self.connection_strength[new_neighbor] = 0.5\n",
    "\n",
    "    def update_state(self, new_state, memory):\n",
    "        self.state = new_state\n",
    "        self.memory.append(memory)\n",
    "\n",
    "    def get_recent_memory(self):\n",
    "        return self.memory[-10:]  # Return the last 10 states\n",
    "\n",
    "# Function to get neighboring cells based on selector\n",
    "def get_neighbors(cell):\n",
    "    neighbors = []\n",
    "    # for di in range(-1, 2):\n",
    "    #     for dj in range(-1, 2):\n",
    "    #         if di == 0 and dj == 0:\n",
    "    #             continue  # Skip the cell itself\n",
    "    #         ni, nj = cell.x + di, cell.y + dj\n",
    "    #         if 0 <= ni < grid_size[0] and 0 <= nj < grid_size[1] and cell.selector[ni][nj]:\n",
    "    #             neighbors.append(ca_grid[ni][nj])\n",
    "    for i in cell.neighbors:\n",
    "        neighbors.append(ca_grid[i[0], i[1]])\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "# Define the cell update logic for continuous values\n",
    "def update_cell_state(cell, neighbors):\n",
    "    new_state = cell.activation_function(neighbors)\n",
    "    new_reward = new_state\n",
    "\n",
    "    # Create an array to hold neighbor data\n",
    "    # neighbors_data = []\n",
    "    # for neighbor in neighbors:\n",
    "    #     # Extract x, y coordinates and state of each neighbor\n",
    "    #     neighbor_data = [neighbor.x, neighbor.y, neighbor.state, neighbor.reward]\n",
    "    #     neighbors_data.append(neighbor_data)\n",
    "\n",
    "    # # Save the new state and the neighbor data in memory\n",
    "    # memory = [[new_state, new_reward], neighbors_data]\n",
    "    memory = [new_state, new_reward]\n",
    "    cell.update_state(new_state, memory)\n",
    "\n",
    "# Define your activation functions and their weights\n",
    "activation_functions = [average_activation, inverted_average, sigmoid_activation, min_activation, max_activation, tanh_activation, random_activation]\n",
    "weights = [1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7] #[0.4, 0.1, 0.07, 0.16, 0.16, 0.07, 0.04]  # Adjust these weights as needed\n",
    "\n",
    "\n",
    "# Learning mechanism\n",
    "def apply_learning(cell):\n",
    "    average_rewards = sum([m[1] for m in cell.get_recent_memory()]) / len(cell.get_recent_memory())\n",
    "\n",
    "    if average_rewards < 0.2:\n",
    "        chosen_function = np.random.choice(activation_functions, p=weights)\n",
    "        cell.activation_function = chosen_function\n",
    "\n",
    "    if average_rewards > 0.2 and average_rewards < 0.85:  # Low average reward\n",
    "        neighbors = get_neighbors(cell)\n",
    "\n",
    "        # Find the neighbor with the lowest sum of states over the last 10 memories\n",
    "        lowest_sum_neighbor = None\n",
    "        lowest_sum = float('inf')\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            neighbor_memory = neighbor.get_recent_memory()\n",
    "            sum_states = sum([m[1] for m in neighbor_memory])  # Sum of rewards\n",
    "\n",
    "            if sum_states < lowest_sum:\n",
    "                lowest_sum = sum_states\n",
    "                lowest_sum_neighbor = neighbor\n",
    "\n",
    "        # If a neighbor with the lowest sum is found, update its selector in the current cell\n",
    "        if lowest_sum_neighbor:\n",
    "            index_of_neighbor = cell.neighbors.index((lowest_sum_neighbor.x, lowest_sum_neighbor.y))\n",
    "            cell.update_selector(update_cells=[index_of_neighbor])\n",
    "        \n",
    "# Initialize the CA grid with Cell objects\n",
    "grid_size = (100, 100)\n",
    "ca_grid = np.empty(grid_size, dtype=object)\n",
    "cycle_length = 5\n",
    "for i in range(grid_size[0]):\n",
    "    for j in range(grid_size[1]):\n",
    "        chosen_function = np.random.choice(activation_functions, p=weights)\n",
    "        ca_grid[i, j] = Cell(i, j, chosen_function)\n",
    "        ca_grid[i, j].state = np.random.rand()\n",
    "        ca_grid[i, j].update_selector()\n",
    "\n",
    "# Main simulation loop\n",
    "simulation_steps = 1000\n",
    "for step in range(simulation_steps):\n",
    "    # Update each cell based on rules\n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            cell = ca_grid[i, j]\n",
    "            neighbors = get_neighbors(cell)\n",
    "            update_cell_state(cell, neighbors)\n",
    "            if step % cycle_length == 0:\n",
    "                apply_learning(cell)\n",
    "    print(step)\n",
    "    \n",
    "    # Save as image for visualization\n",
    "    save_grid_data(ca_grid, step, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBER\\AppData\\Local\\Temp\\ipykernel_17836\\1249633778.py:63: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(file_path))\n"
     ]
    }
   ],
   "source": [
    "create_images_from_csv(experiment_dir)\n",
    "create_gif(experiment_dir, 'ca_simulation.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random ideas\n",
    "* Now that we have the cellular automata engine, it's time to make it think. The basic idea is to have it's selector function decide which neighbors it looks for, probably up to the maximum of 8 it coulde have around it spatially. We can intialize them entirely randomly, or simply start with it's base neighbors.\n",
    "* To get useful inputs and outputs, we need to have certain neurons represent inputs, and others represent outputs. For instance, we could encode some information in the continuous value of input neurons, with more neurons used for more complex information, and have the available actions mapped to certain outputs (ideally these outputs would be more arbitary and less hard-coded somehow in the future).\n",
    "* The learning mechanism will be reward driven using an economic distribution sort of appraoch similar to the suggestions given by Joscha Bach in the Generalist AI talk between Joscha Bach and Michael Levin. We will attempt to track how much each neuron contributes to the final reward.\n",
    "* Input neurons would be rewarded more for keeping the input information to encourage the system to keep the information.\n",
    "* A basic training test we can imagine is a simple addition algorithm. For instance, we can create a simple 4 bit adder. To do so, we will have 2 sets of 4 cell inputs, and one set of a 4 bit output with a carry output.\n",
    "* If a cell is negatively contributing to the loss function (or whatever metric we use to evaluate the result), cells will weaken their connection to it and eventually seek new neighbors, and if they're positively contributing cells will strengthen their connection. This can draw on the cells memory in some fashion as well.\n",
    "* If a cell is itself negatively contributing to the loss function, it will randomly seek new neighbors in a hope to eventually contribute.\n",
    "* Unlike a traditional neural net which would be trained and then ran in inference, the training of this automata would be continuously ongoing. I'll need to add ways to interact with it live to help test how resistant it is to perturbations over time and learning entirely new tasks within the network, for isntance starting with a 2 bit adder, upping it to 4, upping that to 8, etc.\n",
    "* Since information would take time to propagate through the network and calculate (unless there was somehow direct connections to the task, but in practice the tasks should be too complex for such simple connections), the method by which rewards are propagated through the network should probably be analyzed every x steps or something of the sort. The memory could in theory play some sort of part in this, and in general it seems to line up with my recent thoughts on the importance of brain-wave like patterns in intelligence in general. This could in practice mean we can give a new input and read the output every x steps, say 10, making the network have an effective processing time of x steps * time per step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralizedIntelligentAutomata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
